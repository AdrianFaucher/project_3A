{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4534f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from src.data_reading import parse_galaxy_data\n",
    "from src.data_treatment_tools import add_radian_columns, new_CoM_procedure \n",
    "from src.data_display import    (display_hubble_MW, \n",
    "                                display_velocities_distance, \n",
    "                                display_velocities_distance_color, \n",
    "                                animated_velocities_distance,\n",
    "                                display_mean_squared_velocity,\n",
    "                                display_velocities_distance_hubble_regression,\n",
    "                                display_mean_squared_velocity_consistent\n",
    "                                )\n",
    "from IPython.display import clear_output\n",
    "import matplotlib as mpl\n",
    "import emcee\n",
    "import corner\n",
    "from getdist import MCSamples, plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af68934",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/new_data_filtre.csv'\n",
    "galaxy_df = pd.read_csv(file_path)\n",
    "add_radian_columns(galaxy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30886475",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m CoM_Name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoM_CenA_M83_0.76\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m row_name\u001b[38;5;241m=\u001b[39mCoM_Name\n\u001b[1;32m----> 6\u001b[0m \u001b[43mnew_CoM_procedure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgalaxy_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgalaxy1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgalaxy2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCoM_Name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgrid_incertainty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(galaxy_df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      8\u001b[0m galaxy_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/data_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mCoM_Name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lg.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Adrian\\Documents\\X\\Stage 3A recherche\\projet\\project_3A\\cleaned_project\\test_on_data\\src\\data_treatment_tools.py:353\u001b[0m, in \u001b[0;36mnew_CoM_procedure\u001b[1;34m(df, galaxy1, galaxy2, m1_barre, row_name, grid_incertainty)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     row_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoM_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mgalaxy1\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mgalaxy2\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(m1_barre)\n\u001b[1;32m--> 353\u001b[0m \u001b[43madd_CoM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgalaxy1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgalaxy2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm1_barre\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrow_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m add_angular_distance(df,galaxy_center\u001b[38;5;241m=\u001b[39mrow_name)\n\u001b[0;32m    355\u001b[0m add_distances(df,galaxy_center\u001b[38;5;241m=\u001b[39mrow_name,grid_incertainty\u001b[38;5;241m=\u001b[39mgrid_incertainty)\n",
      "File \u001b[1;32mc:\\Users\\Adrian\\Documents\\X\\Stage 3A recherche\\projet\\project_3A\\cleaned_project\\test_on_data\\src\\data_treatment_tools.py:47\u001b[0m, in \u001b[0;36madd_CoM\u001b[1;34m(df, galaxy1, galaxy2, m1_barre, row_name)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add a ne row to the dataframe containing the data of the Center of Mass of two given galaxies with a spcify mass_ratio\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03mbetween those two galaxies. This creat a new row in the dataframe with the name CoM_galaxy1_galaxy2_massRatio1\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    m1_barre (float): mass ratio between the galaxy ( here m1_barre = m1/(m1+m2) so m2_barre = m2/(m1+m2) = 1-m1_barre)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m m2_barre \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m m1_barre\n\u001b[1;32m---> 47\u001b[0m d1, ra1, dec1, v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mgalaxy1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m), \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRA_radians\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDec_radians\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV_h\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     49\u001b[0m d2, ra2, dec2, v2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy2,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDis\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy2,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRA_radians\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy2,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDec_radians\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy2,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV_h\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     51\u001b[0m e_d1_min, e_d1_max  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me_Dis_min\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mgalaxy1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me_Dis_max\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "galaxy1=\"NGC5128_CenA\"\n",
    "galaxy2=\"NGC5236_M83\"\n",
    "r=0.76\n",
    "CoM_Name=\"CoM_CenA_M83_0.76\"\n",
    "row_name=CoM_Name\n",
    "new_CoM_procedure(galaxy_df,galaxy1,galaxy2,r,row_name=CoM_Name,grid_incertainty=True)\n",
    "print(galaxy_df.columns)\n",
    "galaxy_df.to_csv(\"data/data_\"+CoM_Name+\"_lg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f575b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/data_'+CoM_Name+'_lg.csv'\n",
    "galaxy_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ccf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=galaxy_df\n",
    "mask = ~df['Name'].str.startswith('CoM_')\n",
    "G = 4.3009e-9  # Constante gravitationnelle en (km/s)² Mpc / M☉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1011696f",
   "metadata": {},
   "source": [
    "# Minor Infall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e294f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.to_numeric(df.loc[mask, 'dis_center_'+row_name], errors='coerce').values\n",
    "y = pd.to_numeric(df.loc[mask,\"minor_infall_velocity_\"+row_name], errors='coerce').values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "col_e_x_max = 'e_dis_center_max_' + row_name\n",
    "col_e_x_min = 'e_dis_center_min_' + row_name\n",
    "col_e_y_max = 'e_major_infall_velocity_max_'+ row_name\n",
    "col_e_y_min = 'e_minor_infall_velocity_min_'+ row_name\n",
    "\n",
    "if col_e_y_max in df.columns and col_e_y_min in df.columns and col_e_x_min in df.columns and col_e_x_max in df.columns:\n",
    "    e_x_min = pd.to_numeric(df.loc[mask, col_e_x_min], errors='coerce').values\n",
    "    e_x_max = pd.to_numeric(df.loc[mask, col_e_x_max], errors='coerce').values\n",
    "    e_y_min = pd.to_numeric(df.loc[mask, col_e_y_min], errors='coerce').values\n",
    "    e_y_max = pd.to_numeric(df.loc[mask, col_e_y_max], errors='coerce').values\n",
    "    ax.errorbar(x, y, xerr=[e_x_min,e_x_max],yerr=[e_y_min,e_y_max],color=\"black\",markersize=5, fmt='o', capsize=5, ecolor='red')#, label=r\"$v_{r,\\text{\"+velocities[i]+r\"}}$ with exact error\")\n",
    "\n",
    "# ax.set_xlabel(\"Distance from \"+row_name+\" (Mpc)\")\n",
    "# ax.set_ylabel(r\"$v_{r,\\text{\"+velocities[i]+r\"}}$ (km/s)\")\n",
    "ax.set_xlabel(\"Distance from CoM (Mpc)\")\n",
    "ax.set_ylabel(r\"$v_{r}$ (km/s)\")\n",
    "# ax.set_title(r\"$V_{r,\\text{\"+velocities[i]+r\"}}$ depending on distance from \"+row_name)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "ax.set_xlim(0, 15)  # Limites de l'axe x entre 1 et 5\n",
    "ax.set_ylim(-300, 1000)  # Limites de l'axe y entre -25 et 20\n",
    "\n",
    "\n",
    "\n",
    "# hubble\n",
    "def velocity_model(r, H0=70, M=10**12):\n",
    "    \"\"\"\n",
    "    r: distance en mètres\n",
    "    H0: constante de Hubble en s⁻¹\n",
    "    M: masse en kg\n",
    "    Ω_Λ = 0.67 (fixé)\n",
    "    \n",
    "    Retourne la vitesse prédite en m/s\n",
    "    \"\"\"\n",
    "    Omega_Lambda = 0.67\n",
    "    t0 = 0.96 / H0\n",
    "    \n",
    "    term1 = H0* (1.1 + 0.31 * Omega_Lambda  ) * r \n",
    "    term2 = 1.1 * np.sqrt(G * M / r)\n",
    "    \n",
    "    return term1 - term2 \n",
    "\n",
    "r=np.linspace(0.5,15,300)\n",
    "v_r=velocity_model(r)\n",
    "ax.plot(r,v_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_velocity_minor_model(df, mask, row_name,xmin=1,plot=True):\n",
    "    # -------------------\n",
    "    # 1. Data preparation\n",
    "    # -------------------\n",
    "    df_clean = df.loc[mask, [\n",
    "        'dis_center_' + row_name,\n",
    "        'minor_infall_velocity_' + row_name,\n",
    "        'e_dis_center_min_' + row_name,\n",
    "        'e_dis_center_max_' + row_name,\n",
    "        'e_minor_infall_velocity_min_' + row_name,\n",
    "        'e_minor_infall_velocity_max_' + row_name\n",
    "    ]].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "    x = df_clean['dis_center_' + row_name].values\n",
    "    y = df_clean['minor_infall_velocity_' + row_name].values\n",
    "\n",
    "    xerr_low_full = df_clean['e_dis_center_min_' + row_name].values\n",
    "    xerr_high_full = df_clean['e_dis_center_max_' + row_name].values\n",
    "    yerr_low_full = df_clean['e_minor_infall_velocity_min_' + row_name].values\n",
    "    yerr_high_full = df_clean['e_minor_infall_velocity_max_' + row_name].values\n",
    "\n",
    "    # Apply the (0.5 <= x <= 5) mask uniformly\n",
    "    mask_fit = (x >= xmin) & (x <= 4.5)\n",
    "    x = x[mask_fit]\n",
    "    y = y[mask_fit]\n",
    "    xerr_low = xerr_low_full[mask_fit]\n",
    "    xerr_high = xerr_high_full[mask_fit]\n",
    "    yerr_low = yerr_low_full[mask_fit]\n",
    "    yerr_high = yerr_high_full[mask_fit]\n",
    "    \n",
    "    # Calculate symmetrized errors for MCMC (missing in original)\n",
    "    xerr_sym = (xerr_low + xerr_high) / 2\n",
    "    yerr_sym = (yerr_low + yerr_high) / 2\n",
    "\n",
    "    # -------------------\n",
    "    # 2. Define the model\n",
    "    # -------------------\n",
    "    def velocity_model(r, H0, M):\n",
    "        Omega_Lambda = 0.67\n",
    "\n",
    "        # Avoid numerical issues with the square root\n",
    "        if M <= 0:\n",
    "            return np.full_like(r, np.nan)  # avoid sqrt of negative mass\n",
    "        \n",
    "        term1 = H0 * (1.1 + 0.31 * Omega_Lambda) * r\n",
    "        \n",
    "        # Check if the term inside sqrt will be negative\n",
    "        sqrt_term = G * M / r\n",
    "        valid_points = sqrt_term > 0\n",
    "        \n",
    "        result = np.full_like(r, np.nan)\n",
    "        if np.any(valid_points):\n",
    "            result[valid_points] = term1[valid_points] - 1.1 * np.sqrt(sqrt_term[valid_points])\n",
    "            \n",
    "        return result\n",
    "\n",
    "    # -------------------\n",
    "    # 3. Log-likelihood\n",
    "    # -------------------\n",
    "    def total_velocity_error(r, v_err, r_err, H0, M):\n",
    "        # Calculate the derivative df/dx numerically\n",
    "        dr = 1e-5 * r  # small relative step\n",
    "        f_plus = velocity_model(r + dr, H0, M)\n",
    "        f_minus = velocity_model(r - dr, H0, M)\n",
    "        df_dx = (f_plus - f_minus) / (2 * dr)\n",
    "\n",
    "        # Now compute total error\n",
    "        return np.sqrt(v_err**2 + (df_dx * r_err)**2)\n",
    "\n",
    "    def log_likelihood(theta, r, r_err, v, v_err):\n",
    "        H0, M = theta\n",
    "        model = velocity_model(r, H0, M)\n",
    "        if not np.all(np.isfinite(model)):\n",
    "            return -np.inf\n",
    "    \n",
    "        # Total error including propagated uncertainty from r\n",
    "        v_total_err = total_velocity_error(r, v_err, r_err, H0, M)\n",
    "        if not np.all(np.isfinite(v_total_err)) or np.any(v_total_err == 0):\n",
    "            return -np.inf\n",
    "    \n",
    "        return -0.5 * np.sum(((v - model) / v_total_err)**2 + np.log(2 * np.pi * v_total_err**2))\n",
    "\n",
    "    def log_prior(theta,H0_prior=False,M_prior=False):\n",
    "        H0, M = theta\n",
    "        if H0_prior:\n",
    "            if 1e11 < M < 1e14:\n",
    "                logp_H0 = -0.5 * ((H0 - 73) / 1.0)**2 - np.log(np.sqrt(2 * np.pi) * 1.0)\n",
    "                return logp_H0\n",
    "            return -np.inf\n",
    "        \n",
    "        elif M_prior:\n",
    "            \n",
    "            if 30 < H0 < 90 and M > 0:\n",
    "                # Gaussian prior on M: mean=3e12, sigma=1e12\n",
    "                logp_M = -0.5 * ((M - 3e12) / 1e12)**2 - np.log(np.sqrt(2 * np.pi) * 1e12)\n",
    "                return logp_M\n",
    "        else:\n",
    "            if 30 < H0 < 150 and 0 < M < 1e14:\n",
    "                return 0.0  # flat prior\n",
    "            return -np.inf  # log(0)\n",
    "        return -np.inf\n",
    "\n",
    "    def log_probability(theta, r, r_err, v, v_err):\n",
    "        lp = log_prior(theta)\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "        return lp + log_likelihood(theta, r, r_err, v, v_err)\n",
    "\n",
    "    # -------------------\n",
    "    # 4. Run MCMC\n",
    "    # -------------------\n",
    "    ndim = 2\n",
    "    nwalkers = 32\n",
    "    p0 = np.array([70, 1e12]) + 1e-4 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "    sampler_min = emcee.EnsembleSampler(nwalkers, ndim, log_probability, \n",
    "                                     args=(x, xerr_sym, y, yerr_sym))\n",
    "    sampler_min.run_mcmc(p0, 5000, progress=True)\n",
    "\n",
    "    # Get the flat samples (renamed from the original)\n",
    "    samples_min = sampler_min.get_chain(discard=1000, thin=15, flat=True)\n",
    "\n",
    "    # -------------------\n",
    "    # 5. Use GetDist for posterior plots\n",
    "    # -------------------\n",
    "    if plot:\n",
    "        names = ['H0', 'M']\n",
    "        labels = [r'H_0', r'M \\,[kg]']  # LaTeX labels\n",
    "\n",
    "        # Create MCSamples object from your MCMC samples\n",
    "        gdsamples_min = MCSamples(samples=samples_min, names=names, labels=labels)\n",
    "\n",
    "        # Create the triangle plot\n",
    "        g = plots.get_subplot_plotter()\n",
    "        g.triangle_plot(gdsamples_min, filled=True)\n",
    "        plt.show()\n",
    "\n",
    "        # -------------------\n",
    "        # 6. Plot best-fit model\n",
    "        # -------------------\n",
    "        H0_mcmc, M_mcmc = np.median(samples_min, axis=0)\n",
    "\n",
    "\n",
    "        H0_lower, M_lower = np.percentile(samples_min, 16, axis=0)\n",
    "        H0_upper, M_upper = np.percentile(samples_min, 84, axis=0)\n",
    "\n",
    "        # Compute uncertainties\n",
    "        H0_uncertainty = 0.5 * (H0_upper - H0_lower)\n",
    "        M_uncertainty = 0.5 * (M_upper - M_lower)\n",
    "\n",
    "        # Fine grid\n",
    "        r_plot = np.linspace(xmin, 15, 500)\n",
    "        v_median = velocity_model(r_plot, H0_mcmc, M_mcmc)\n",
    "\n",
    "        # Sample 100 posterior draws to make uncertainty band\n",
    "        v_samples_min = np.array([velocity_model(r_plot, h0, m) for h0, m in samples_min[np.random.choice(len(samples_min), 1000, replace=False)]])\n",
    "\n",
    "        v_lower = np.percentile(v_samples_min, 0.15, axis=0)\n",
    "        v_upper = np.percentile(v_samples_min, 99.15, axis=0)\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.errorbar(x, y, xerr=[xerr_low, xerr_high], yerr=[yerr_low, yerr_high],\n",
    "                    fmt='o', color='black', ecolor='red', capsize=5, label='Data')\n",
    "\n",
    "        ax.plot(r_plot, v_median, 'r-', color='blue',label=(rf\"Fit: $H_0 = {H0_mcmc:.1f} \\pm {H0_uncertainty:.1f}$\"+ \"\\n\"+ rf\"$M = ({M_mcmc/1e12:.2f} \\pm {M_uncertainty/1e12:.2f}) \\times 10^{{12}}\\, M_\\odot$\"))\n",
    "        ax.fill_between(r_plot, v_lower, v_upper, color='blue', alpha=0.3, label=rf\"$3\\sigma$ credible interval\")\n",
    "\n",
    "        ax.set_xlabel(\"Distance from CoM (Mpc)\")\n",
    "        ax.set_ylabel(r\"$v{r}$ (km/s)\")\n",
    "        ax.grid(True)\n",
    "        ax.set_xlim(0, 15)\n",
    "        ax.set_ylim(-300, 1000)\n",
    "        ax.legend()\n",
    "        plt.plot()\n",
    "        return H0_mcmc, H0_uncertainty, M_mcmc, M_uncertainty, samples_min\n",
    "    else:\n",
    "        H0_mcmc, M_mcmc = np.median(samples_min, axis=0)\n",
    "        H0_lower, M_lower = np.percentile(samples_min, 16, axis=0)\n",
    "        H0_upper, M_upper = np.percentile(samples_min, 84, axis=0)\n",
    "        H0_uncertainty = 0.5 * (H0_upper - H0_lower)\n",
    "        M_uncertainty = 0.5 * (M_upper - M_lower)\n",
    "        return H0_mcmc, H0_uncertainty, M_mcmc, M_uncertainty, samples_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5381ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "H0,H0_sigma, M,M_sigma, samples_min  = analyze_velocity_minor_model(df, mask, row_name, xmin=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vecteur r (de 0 à 4, 10 points)\n",
    "r_plot = np.linspace(0, 2.5, 10)\n",
    "\n",
    "H_values = []\n",
    "H_sigmas = []\n",
    "M_values = []\n",
    "M_sigmas = []\n",
    "# Remplissage des valeurs\n",
    "for k in r_plot:\n",
    "    H0, H0_sigma, M , M_sigma, _ = analyze_velocity_minor_model(df, mask, row_name, xmin=k,plot= False)\n",
    "    H_values.append(H0)\n",
    "    H_sigmas.append(H0_sigma)\n",
    "    M_values.append(M)\n",
    "    M_sigmas.append(M_sigma)\n",
    "\n",
    "# Création de la figure\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Axe primaire pour H\n",
    "ax1.set_xlabel(\"r\")\n",
    "ax1.set_ylabel(\"H\", color=\"tab:blue\")\n",
    "ax1.plot(r_plot, H_values, marker='o', color=\"tab:blue\", label=\"H\")\n",
    "ax1.fill_between(r_plot,\n",
    "                 np.array(H_values) - np.array(H_sigmas),\n",
    "                 np.array(H_values) + np.array(H_sigmas),\n",
    "                 color=\"tab:blue\", alpha=0.2, label=\"H uncertainty\")\n",
    "ax1.tick_params(axis='y', labelcolor=\"tab:blue\")\n",
    "\n",
    "# Axe secondaire pour M\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"M\", color=\"tab:red\")\n",
    "ax2.plot(r_plot, M_values, marker='s', linestyle='--', color=\"tab:red\", label=\"M\")\n",
    "ax2.fill_between(r_plot,\n",
    "                 np.array(M_values) - np.array(M_sigmas),\n",
    "                 np.array(M_values) + np.array(M_sigmas),\n",
    "                 color=\"tab:red\", alpha=0.2, label=\"M uncertainty\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"tab:red\")\n",
    "\n",
    "# Titre et mise en page\n",
    "plt.title(\"Évolution de H et M en fonction de r\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5899ff",
   "metadata": {},
   "source": [
    "# Major infall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.to_numeric(df.loc[mask, 'dis_center_'+row_name], errors='coerce').values\n",
    "y = pd.to_numeric(df.loc[mask,\"major_infall_velocity_\"+row_name], errors='coerce').values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "col_e_x_max = 'e_dis_center_max_' + row_name\n",
    "col_e_x_min = 'e_dis_center_min_' + row_name\n",
    "col_e_y_max = 'e_major_infall_velocity_max_'+ row_name\n",
    "col_e_y_min = 'e_major_infall_velocity_min_'+ row_name\n",
    "\n",
    "if col_e_y_max in df.columns and col_e_y_min in df.columns and col_e_x_min in df.columns and col_e_x_max in df.columns:\n",
    "    e_x_min = pd.to_numeric(df.loc[mask, col_e_x_min], errors='coerce').values\n",
    "    e_x_max = pd.to_numeric(df.loc[mask, col_e_x_max], errors='coerce').values\n",
    "    e_y_min = pd.to_numeric(df.loc[mask, col_e_y_min], errors='coerce').values\n",
    "    e_y_max = pd.to_numeric(df.loc[mask, col_e_y_max], errors='coerce').values\n",
    "    ax.errorbar(x, y, xerr=[e_x_min,e_x_max],yerr=[e_y_min,e_y_max],color=\"black\",markersize=5, fmt='o', capsize=5, ecolor='red')#, label=r\"$v_{r,\\text{\"+velocities[i]+r\"}}$ with exact error\")\n",
    "\n",
    "# ax.set_xlabel(\"Distance from \"+row_name+\" (Mpc)\")\n",
    "# ax.set_ylabel(r\"$v_{r,\\text{\"+velocities[i]+r\"}}$ (km/s)\")\n",
    "ax.set_xlabel(\"Distance from CoM (Mpc)\")\n",
    "ax.set_ylabel(r\"$v_{r}$ (km/s)\")\n",
    "# ax.set_title(r\"$V_{r,\\text{\"+velocities[i]+r\"}}$ depending on distance from \"+row_name)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "ax.set_xlim(0, 15)  # Limites de l'axe x entre 1 et 5\n",
    "ax.set_ylim(-300, 1000)  # Limites de l'axe y entre -25 et 20\n",
    "\n",
    "\n",
    "\n",
    "# hubble\n",
    "def velocity_model(r, H0=70, M=10**12):\n",
    "    \"\"\"\n",
    "    r: distance en mètres\n",
    "    H0: constante de Hubble en s⁻¹\n",
    "    M: masse en kg\n",
    "    Ω_Λ = 0.67 (fixé)\n",
    "    \n",
    "    Retourne la vitesse prédite en m/s\n",
    "    \"\"\"\n",
    "    Omega_Lambda = 0.67\n",
    "    t0 = 0.96 / H0\n",
    "    \n",
    "    term1 = H0* (1.1 + 0.31 * Omega_Lambda  ) * r \n",
    "    term2 = 1.1 * np.sqrt(G * M / r)\n",
    "    \n",
    "    return term1 - term2 \n",
    "\n",
    "r=np.linspace(0.5,15,300)\n",
    "v_r=velocity_model(r)\n",
    "ax.plot(r,v_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_velocity_major_model(df, mask, row_name,xmin=1,plot=True):\n",
    "    # -------------------\n",
    "    # 1. Data preparation\n",
    "    # -------------------\n",
    "    df_clean = df.loc[mask, [\n",
    "        'dis_center_' + row_name,\n",
    "        'major_infall_velocity_' + row_name,\n",
    "        'e_dis_center_min_' + row_name,\n",
    "        'e_dis_center_max_' + row_name,\n",
    "        'e_major_infall_velocity_min_' + row_name,\n",
    "        'e_major_infall_velocity_max_' + row_name\n",
    "    ]].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "    x = df_clean['dis_center_' + row_name].values\n",
    "    y = df_clean['major_infall_velocity_' + row_name].values\n",
    "\n",
    "    xerr_low_full = df_clean['e_dis_center_min_' + row_name].values\n",
    "    xerr_high_full = df_clean['e_dis_center_max_' + row_name].values\n",
    "    yerr_low_full = df_clean['e_major_infall_velocity_min_' + row_name].values\n",
    "    yerr_high_full = df_clean['e_major_infall_velocity_max_' + row_name].values\n",
    "\n",
    "    # Apply the (0.5 <= x <= 5) mask uniformly\n",
    "    mask_fit = (x >= xmin) & (x <= 5)\n",
    "    x = x[mask_fit]\n",
    "    y = y[mask_fit]\n",
    "    xerr_low = xerr_low_full[mask_fit]\n",
    "    xerr_high = xerr_high_full[mask_fit]\n",
    "    yerr_low = yerr_low_full[mask_fit]\n",
    "    yerr_high = yerr_high_full[mask_fit]\n",
    "    \n",
    "    # Calculate symmetrized errors for MCMC (missing in original)\n",
    "    xerr_sym = (xerr_low + xerr_high) / 2\n",
    "    yerr_sym = (yerr_low + yerr_high) / 2\n",
    "\n",
    "    # -------------------\n",
    "    # 2. Define the model\n",
    "    # -------------------\n",
    "    def velocity_model(r, H0, M):\n",
    "        Omega_Lambda = 0.67\n",
    "\n",
    "        # Avoid numerical issues with the square root\n",
    "        if M <= 0:\n",
    "            return np.full_like(r, np.nan)  # avoid sqrt of negative mass\n",
    "        \n",
    "        term1 = H0 * (1.1 + 0.31 * Omega_Lambda) * r\n",
    "        \n",
    "        # Check if the term inside sqrt will be negative\n",
    "        sqrt_term = G * M / r\n",
    "        valid_points = sqrt_term > 0\n",
    "        \n",
    "        result = np.full_like(r, np.nan)\n",
    "        if np.any(valid_points):\n",
    "            result[valid_points] = term1[valid_points] - 1.1 * np.sqrt(sqrt_term[valid_points])\n",
    "            \n",
    "        return result\n",
    "\n",
    "    # -------------------\n",
    "    # 3. Log-likelihood\n",
    "    # -------------------\n",
    "    def total_velocity_error(r, v_err, r_err, H0, M):\n",
    "        # Calculate the derivative df/dx numerically\n",
    "        dr = 1e-5 * r  # small relative step\n",
    "        f_plus = velocity_model(r + dr, H0, M)\n",
    "        f_minus = velocity_model(r - dr, H0, M)\n",
    "        df_dx = (f_plus - f_minus) / (2 * dr)\n",
    "\n",
    "        # Now compute total error\n",
    "        return np.sqrt(v_err**2 + (df_dx * r_err)**2)\n",
    "\n",
    "    def log_likelihood(theta, r, r_err, v, v_err):\n",
    "        H0, M = theta\n",
    "        model = velocity_model(r, H0, M)\n",
    "        if not np.all(np.isfinite(model)):\n",
    "            return -np.inf\n",
    "    \n",
    "        # Total error including propagated uncertainty from r\n",
    "        v_total_err = total_velocity_error(r, v_err, r_err, H0, M)\n",
    "        if not np.all(np.isfinite(v_total_err)) or np.any(v_total_err == 0):\n",
    "            return -np.inf\n",
    "    \n",
    "        return -0.5 * np.sum(((v - model) / v_total_err)**2 + np.log(2 * np.pi * v_total_err**2))\n",
    "\n",
    "    def log_prior(theta,H0_prior=False,M_prior=False):\n",
    "        H0, M = theta\n",
    "        if H0_prior:\n",
    "            if 1e11 < M < 1e14:\n",
    "                logp_H0 = -0.5 * ((H0 - 73) / 1.0)**2 - np.log(np.sqrt(2 * np.pi) * 1.0)\n",
    "                return logp_H0\n",
    "            return -np.inf\n",
    "        \n",
    "        elif M_prior:\n",
    "            \n",
    "            if 30 < H0 < 90 and M > 0:\n",
    "                # Gaussian prior on M: mean=3e12, sigma=1e12\n",
    "                logp_M = -0.5 * ((M - 3e12) / 1e12)**2 - np.log(np.sqrt(2 * np.pi) * 1e12)\n",
    "                return logp_M\n",
    "        else:\n",
    "            if 30 < H0 < 150 and 0 < M < 1e14:\n",
    "                return 0.0  # flat prior\n",
    "            return -np.inf  # log(0)\n",
    "        return -np.inf\n",
    "\n",
    "    def log_probability(theta, r, r_err, v, v_err):\n",
    "        lp = log_prior(theta)\n",
    "        if not np.isfinite(lp):\n",
    "            return -np.inf\n",
    "        return lp + log_likelihood(theta, r, r_err, v, v_err)\n",
    "\n",
    "    # -------------------\n",
    "    # 4. Run MCMC\n",
    "    # -------------------\n",
    "    ndim = 2\n",
    "    nwalkers = 32\n",
    "    p0 = np.array([70, 1e12]) + 1e-4 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "    sampler_maj = emcee.EnsembleSampler(nwalkers, ndim, log_probability, \n",
    "                                     args=(x, xerr_sym, y, yerr_sym))\n",
    "    sampler_maj.run_mcmc(p0, 5000, progress=True)\n",
    "\n",
    "    # Get the flat samples (renamed from the original)\n",
    "    samples_maj = sampler_maj.get_chain(discard=1000, thin=15, flat=True)\n",
    "\n",
    "    # -------------------\n",
    "    # 5. Use GetDist for posterior plots\n",
    "    # -------------------\n",
    "    if plot:\n",
    "        names = ['H0', 'M']\n",
    "        labels = [r'H_0', r'M \\,[kg]']  # LaTeX labels\n",
    "\n",
    "        # Create MCSamples object from your MCMC samples\n",
    "        gdsamples_maj = MCSamples(samples=samples_maj, names=names, labels=labels)\n",
    "\n",
    "        # Create the triangle plot\n",
    "        g = plots.get_subplot_plotter()\n",
    "        g.triangle_plot(gdsamples_maj, filled=True)\n",
    "        plt.show()\n",
    "\n",
    "        # -------------------\n",
    "        # 6. Plot best-fit model\n",
    "        # -------------------\n",
    "        H0_mcmc, M_mcmc = np.median(samples_maj, axis=0)\n",
    "\n",
    "\n",
    "        H0_lower, M_lower = np.percentile(samples_maj, 16, axis=0)\n",
    "        H0_upper, M_upper = np.percentile(samples_maj, 84, axis=0)\n",
    "\n",
    "        # Compute uncertainties\n",
    "        H0_uncertainty = 0.5 * (H0_upper - H0_lower)\n",
    "        M_uncertainty = 0.5 * (M_upper - M_lower)\n",
    "\n",
    "        # Fine grid\n",
    "        r_plot = np.linspace(1, 15, 500)\n",
    "        v_median = velocity_model(r_plot, H0_mcmc, M_mcmc)\n",
    "\n",
    "        # Sample 100 posterior draws to make uncertainty band\n",
    "        v_samples_maj = np.array([velocity_model(r_plot, h0, m) for h0, m in samples_maj[np.random.choice(len(samples_maj), 1000, replace=False)]])\n",
    "\n",
    "        v_lower = np.percentile(v_samples_maj, 0.15, axis=0)\n",
    "        v_upper = np.percentile(v_samples_maj, 99.85, axis=0)\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.errorbar(x, y, xerr=[xerr_low, xerr_high], yerr=[yerr_low, yerr_high],\n",
    "                    fmt='o', color='black', ecolor='red', capsize=5, label='Data')\n",
    "        ax.plot(r_plot,v_median,color='blue',label=(rf\"Fit: $H_0 = {H0_mcmc:.1f} \\pm {H0_uncertainty:.1f}$\"+ \"\\n\"+ rf\"$M = ({M_mcmc/1e12:.2f} \\pm {M_uncertainty/1e12:.2f}) \\times 10^{{12}}\\, M_\\odot$\"))    \n",
    "        ax.fill_between(r_plot, v_lower, v_upper, color='blue', alpha=0.3, label=rf\"$3\\sigma$ credible interval\")\n",
    "\n",
    "        ax.set_xlabel(\"Distance from CoM (Mpc)\")\n",
    "        ax.set_ylabel(r\"$v{r}$ (km/s)\")\n",
    "        ax.grid(True)\n",
    "        ax.set_xlim(0, 15)\n",
    "        ax.set_ylim(-300, 1000)\n",
    "        ax.legend()\n",
    "\n",
    "        return H0_mcmc, H0_uncertainty, M_mcmc, M_uncertainty, samples_min\n",
    "    else:\n",
    "        H0_mcmc, M_mcmc = np.median(samples_maj, axis=0)\n",
    "        H0_lower, M_lower = np.percentile(samples_maj, 16, axis=0)\n",
    "        H0_upper, M_upper = np.percentile(samples_maj, 84, axis=0)\n",
    "        H0_uncertainty = 0.5 * (H0_upper - H0_lower)\n",
    "        M_uncertainty = 0.5 * (M_upper - M_lower)\n",
    "        return H0_mcmc, H0_uncertainty, M_mcmc, M_uncertainty, samples_min\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "H0, H0_sigma, M , M_sigma, samples_maj = analyze_velocity_major_model(galaxy_df, mask, row_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vecteur r (de 0 à 4, 10 points)\n",
    "r_plot = np.linspace(0, 2.5, 10)\n",
    "\n",
    "H_values = []\n",
    "H_sigmas = []\n",
    "M_values = []\n",
    "M_sigmas = []\n",
    "# Remplissage des valeurs\n",
    "for k in r_plot:\n",
    "    H0, H0_sigma, M , M_sigma, _ = analyze_velocity_major_model(df, mask, row_name, xmin=k,plot= False)\n",
    "    H_values.append(H0)\n",
    "    H_sigmas.append(H0_sigma)\n",
    "    M_values.append(M)\n",
    "    M_sigmas.append(M_sigma)\n",
    "\n",
    "# Création de la figure\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Axe primaire pour H\n",
    "ax1.set_xlabel(\"r\")\n",
    "ax1.set_ylabel(\"H\", color=\"tab:blue\")\n",
    "ax1.plot(r_plot, H_values, marker='o', color=\"tab:blue\", label=\"H\")\n",
    "ax1.fill_between(r_plot,\n",
    "                 np.array(H_values) - np.array(H_sigmas),\n",
    "                 np.array(H_values) + np.array(H_sigmas),\n",
    "                 color=\"tab:blue\", alpha=0.2, label=\"H uncertainty\")\n",
    "ax1.tick_params(axis='y', labelcolor=\"tab:blue\")\n",
    "\n",
    "# Axe secondaire pour M\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"M\", color=\"tab:red\")\n",
    "ax2.plot(r_plot, M_values, marker='s', linestyle='--', color=\"tab:red\", label=\"M\")\n",
    "ax2.fill_between(r_plot,\n",
    "                 np.array(M_values) - np.array(M_sigmas),\n",
    "                 np.array(M_values) + np.array(M_sigmas),\n",
    "                 color=\"tab:red\", alpha=0.2, label=\"M uncertainty\")\n",
    "ax2.tick_params(axis='y', labelcolor=\"tab:red\")\n",
    "\n",
    "# Titre et mise en page\n",
    "plt.title(\"Évolution de H et M en fonction de r\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['H0', 'M']\n",
    "labels = [r'H_0', r'M \\,[M_o]']  # LaTeX labels\n",
    "\n",
    "# Create MCSamples object from your MCMC samples\n",
    "gdsamples_min = MCSamples(samples=samples_min, names=names, labels=labels)\n",
    "gdsamples_maj = MCSamples(samples=samples_maj, names=names, labels=labels)\n",
    "\n",
    "# Create the triangle plot\n",
    "g = plots.get_subplot_plotter()\n",
    "g.triangle_plot([gdsamples_min, gdsamples_maj], filled=True, \n",
    "                legend_labels=['Minor Infall', 'Major Infall'])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
